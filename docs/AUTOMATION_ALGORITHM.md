# 自動化判別アルゴリズム

> 本ドキュメントは、RPO業務の各タスクに対して自動化可否を判定するための基準を定義する。
> 判定の恣意性を排除し、再現性のある判断を行うために運用する。

---

## 判定プロセス

### Step 1. タスクの分解

判定対象は「サービス」単位ではなく、**作業（タスク）単位**で行う。
「ダイレクトリクルーティング」のような大カテゴリをそのまま判定してはならない。
かならず以下の粒度まで分解する:

```
入力（何を受け取るか）
  → 処理（何をするか）
    → 判断（どこで人間の意思決定が入るか）
      → 操作（どのツール/システムで実行するか）
        → 出力（何が生まれるか）
```

### Step 2. 5軸評価

各タスクに対して、以下の5軸で1〜5点のスコアリングを行う。

| 軸 | 1点（自動化困難） | 3点（条件付きで可能） | 5点（自動化容易） |
|----|-------------------|---------------------|-------------------|
| **A. 入出力の構造化度** | 非構造的（自然言語の対話、暗黙の文脈） | 半構造的（テンプレートはあるがカスタマイズが必要） | 完全構造的（定型フィールド、数値、API） |
| **B. 判断の再現性** | 暗黙知・直感・経験則に依存 | フレームワークはあるが例外処理に人間が必要 | 完全にルール化/パターン化可能 |
| **C. 対人依存度** | リアルタイム対話が本質（信頼構築・感情読取） | 非同期コミュニケーションで代替可能 | 人との接触が不要 |
| **D. 技術的実現性** | 現在の技術では不可能/極めて困難 | 技術的には可能だが品質・安定性に課題 | 既存ツール/APIで安定的に実現可能 |
| **E. 品質担保の難易度** | 出力の正解が主観的・文脈依存。品質判定自体に専門性が必要 | 品質基準は定義可能だが、チェックに人間の介入が必要 | 品質が客観的に測定可能（数値、エラー率等） |

### Step 3. 判定基準

| 合計スコア | 判定 | 定義 |
|-----------|------|------|
| 21〜25点 | **完全自動化** | 人間の介入なしにシステムで実行可能 |
| 16〜20点 | **高度自動化** | 大部分をシステムで実行。人間はレビュー/承認のみ |
| 11〜15点 | **部分自動化** | 一部の工程をシステムで効率化。判断・実行の核は人間 |
| 6〜10点 | **AIアシスト** | AIが補助的な情報提供・下書き生成を行うが、実質的な作業は人間 |
| 5点 | **自動化不可** | 全軸で人間が不可欠 |

### Step 4. 検証チェック

判定後、以下のネガティブチェックを行う:

1. **「それ、本当にAIの出力をそのまま使えるか？」テスト** — 生成物をレビューなしにクライアントや候補者に出せるか。出せないなら「完全自動化」ではない
2. **「壊れたらどうなるか？」テスト** — 自動化が誤動作した場合の影響範囲。採用決定に影響するなら高度自動化以上にはしない
3. **「初回セットアップは誰がやるか？」テスト** — 自動化の前提となる設計・設定自体が専門的な作業なら、その設計作業は別タスクとして評価する

---

## 判定の原則

1. **楽観バイアスを排除する** — 「技術的にできるかもしれない」ではなく「今日、安定的に運用できるか」で判断する
2. **タスクの連鎖を考慮する** — あるタスクが自動化できても、その前後のタスクが人間判断なら、実質的な効果は限定的
3. **セットアップと運用を分離する** — ダッシュボード構築の例: 「何の指標を見るか」の設計（セットアップ）と「データの自動更新」（運用）は別タスク。前者は人間、後者は自動化可能。混同しない
4. **「自動化できる」と「自動化すべき」は別問題** — 技術的に可能でもROIが見合わない場合がある。ただし本判定では「可否」のみを扱い、「すべきか」はR4で判断する
